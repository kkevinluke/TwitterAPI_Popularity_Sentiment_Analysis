{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cuZH4cgg482T"
      },
      "outputs": [],
      "source": [
        "# For sending GET requests from the API\n",
        "import requests\n",
        "# For saving access tokens and for file management when creating and adding to the dataset\n",
        "import os\n",
        "# For dealing with json responses we receive from the API\n",
        "import json\n",
        "# For displaying the data after\n",
        "import pandas as pd\n",
        "# For saving the response data in CSV format\n",
        "import csv\n",
        "# For parsing the dates received from twitter in readable formats\n",
        "import datetime\n",
        "import dateutil.parser\n",
        "import unicodedata\n",
        "#To add wait time between requests\n",
        "import time\n",
        "#Twitter API Connection\n",
        "import tweepy\n",
        "#NLP Library\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zL1603L1xb6E"
      },
      "outputs": [],
      "source": [
        "consumerKey = \"xPfZgxhA6RcRGVd4Ukx2QGxn2\"\n",
        "consumerSecret = \"qJHLTMXYweHuD3royMx157Ew7SX3n2FBFIeaA92a6EorGikELb\"\n",
        "accessToken = \"1427378156-m6V63pdoobv5J3YYrcLPGjetQIhHZc2UeAnB0tl\"\n",
        "accessTokenSecret = \"NIBAsbGQk516HgexRhQlVUaCmJHB8maozVbjhnqTwlBGU\"\n",
        "auth = tweepy.OAuthHandler(consumerKey, consumerSecret)\n",
        "auth.set_access_token(accessToken, accessTokenSecret)\n",
        "api = tweepy.API(auth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "GM2egn3Z694g"
      },
      "outputs": [],
      "source": [
        "tweets = tweepy.Cursor(api.search, q = \"Biden\", lang = \"en\", geocode = \"53.8182212,-3.0564845,235km\").items(3000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keyword = \"Biden\""
      ],
      "metadata": {
        "id": "sp5QvPJc1Ugo"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_list=[]\n",
        "loc_list=[]\n",
        "date_list=[]\n",
        "name=[]\n",
        "followers=[]\n",
        "desc=[]\n",
        "\n",
        "for i in tweets:\n",
        "  print(i._json)\n",
        "  tweet_list.append(i._json[\"text\"])\n",
        "  loc_list.append(i._json[\"user\"][\"location\"])\n",
        "  date_list.append(datetime.datetime.strptime(i._json[\"created_at\"], '%a %b %d %H:%M:%S +0000 %Y').strftime('%d/%m/%Y'))\n",
        "  name.append(i._json[\"user\"][\"name\"])\n",
        "  followers.append(i._json[\"user\"][\"followers_count\"])\n",
        "  desc.append(i._json[\"user\"][\"description\"])\n",
        "  "
      ],
      "metadata": {
        "id": "EgLtGtYHQmiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_dict = {\"date\": date_list, \"name\":name, \"tweet\":tweet_list, \"description\":desc, \"followers\":followers, \"location\":loc_list}"
      ],
      "metadata": {
        "id": "ExHfzrRjYr3H"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tdf = pd.DataFrame(tweet_dict)\n",
        "tdf"
      ],
      "metadata": {
        "id": "jxjtTiJ0en-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download([\n",
        "...     \"names\",\n",
        "...     \"stopwords\",\n",
        "...     \"state_union\",\n",
        "...     \"twitter_samples\",\n",
        "...     \"movie_reviews\",\n",
        "...     \"averaged_perceptron_tagger\",\n",
        "...     \"vader_lexicon\",\n",
        "...     \"punkt\",\n",
        "... ])"
      ],
      "metadata": {
        "id": "kvOb1gjF8v9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = nltk.corpus.stopwords.words(\"english\")"
      ],
      "metadata": {
        "id": "nXBec1bM85HA"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twtstr=str(tweet_list)\n",
        "print(twtstr)\n"
      ],
      "metadata": {
        "id": "56sHWKlc-0ZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=nltk.word_tokenize(twtstr)\n",
        "print(x)\n"
      ],
      "metadata": {
        "id": "ew4zXACVAXYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xp=[]\n",
        "for i in x:\n",
        "  if i.isalpha() ==True:\n",
        "    xp.append(i)\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "xp\n"
      ],
      "metadata": {
        "id": "-g0AdVNXBm1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(xp)"
      ],
      "metadata": {
        "id": "ARz6m92ZHpvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xp_nostop = [w for w in xp if w.lower() not in stopwords]"
      ],
      "metadata": {
        "id": "hYACZTMINLHl"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fd = nltk.FreqDist(xp_nostop)"
      ],
      "metadata": {
        "id": "L9G00zluDDdv"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fd.tabulate(10)"
      ],
      "metadata": {
        "id": "JHB9AqqdDx-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lower_fd = nltk.FreqDist([w.lower() for w in fd])\n",
        "lower_fd"
      ],
      "metadata": {
        "id": "bcsH7aMC9uZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = nltk.Text(xp)\n",
        "text.concordance(\"Biden\", lines=5)"
      ],
      "metadata": {
        "id": "oanHLwn598v6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer \n",
        "sia = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "id": "9V56WyRdNy5S"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,len(tweet_list)):\n",
        "  print(sia.polarity_scores(tweet_list[i]))"
      ],
      "metadata": {
        "id": "ifze3T73ODul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_positive(tweet: str) -> bool:\n",
        "    \"\"\"True if tweet has positive compound sentiment, False otherwise.\"\"\"\n",
        "    return sia.polarity_scores(tweet)[\"compound\"] > 0"
      ],
      "metadata": {
        "id": "iCm3GiAEPqYN"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from random import shuffle\n",
        "shuffle(tweet_list)\n",
        "for t in tweet_list:\n",
        "    print(\">\", is_positive(t), t)"
      ],
      "metadata": {
        "id": "EDz1AxktTNYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_list=[]\n",
        "shuffle(tweet_list)\n",
        "for t in tweet_list:\n",
        "    count_list.append(is_positive(t))\n",
        "\n",
        "\"{pos} POSITIVE Sentiment & , {neg} NEGATIVE Sentiment tweets on a search by keyword {key}\" .format(pos=count_list.count(True), neg=count_list.count(False), key=keyword.upper())\n"
      ],
      "metadata": {
        "id": "IPzCfGhATqog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FKv5nFxg3WK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gQVEAuhqyu09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_xThrJxXy98L"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Twiiter_API_Popularity_senitment_Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}